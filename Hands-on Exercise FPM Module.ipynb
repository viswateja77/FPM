{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-on Exercise for  FPM Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Exploring properties of the dataset accidents_10k.dat. Read more about it here:  http://fimi.uantwerpen.be/data/accidents.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 \r\n",
      "2 5 7 8 9 10 12 13 14 15 16 17 18 20 22 23 24 25 27 28 29 32 33 34 35 36 37 38 39 \r\n",
      "7 10 12 13 14 15 16 17 18 20 25 28 29 30 33 40 41 42 43 44 45 46 47 48 49 50 51 52 \r\n",
      "1 5 8 10 12 14 15 16 17 18 19 20 21 22 24 25 26 27 28 29 30 31 41 43 46 48 49 51 52 53 54 55 56 57 58 59 60 61 \r\n",
      "5 8 10 12 14 15 16 17 18 21 22 24 25 26 27 28 29 31 33 36 38 39 41 43 46 56 62 63 64 65 66 67 68 \r\n",
      "7 8 10 12 17 18 21 23 24 26 27 28 29 30 33 34 35 36 38 41 43 47 59 63 66 69 70 71 72 73 74 75 76 77 78 79 \r\n",
      "1 12 14 15 16 17 18 21 22 23 24 25 27 28 29 30 31 35 38 41 43 44 53 56 57 58 59 60 63 66 80 81 82 83 84 \r\n",
      "10 12 14 15 16 17 18 21 22 24 25 26 27 28 29 30 31 33 39 41 43 44 46 49 59 60 62 63 66 82 \r\n",
      "1 8 10 12 14 15 16 17 18 21 22 23 24 25 27 29 30 31 38 41 43 53 56 59 61 63 66 68 85 86 87 88 89 \r\n",
      "1 8 12 13 14 15 16 17 18 22 24 25 28 30 38 41 42 43 46 49 60 63 64 66 80 82 84 90 91 92 93 94 95 \r\n"
     ]
    }
   ],
   "source": [
    "!head accidents_10k.dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Question 1a:** </span>. How many items are there in the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310\r\n"
     ]
    }
   ],
   "source": [
    "!awk -- '{for (i = 1; i <= NF; i++) wc[$i] += 1}; END {print length(wc)}' accidents_10k.dat "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">**Answer:** </span>itemsets :310"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Question 1b:** </span> How many transactions are present in the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145 accidents_10k.dat\r\n"
     ]
    }
   ],
   "source": [
    "!wc -L accidents_10k.dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">**Answer:** </span> transactions : 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Question 1c:** </span>.  What is the length of the smallest transaction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\r\n"
     ]
    }
   ],
   "source": [
    "!awk '(NR==1||length< smallest){smallest=length} END {print smallest}' accidents_10k.dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">**Answer:** </span> length of smallest transaction : 69"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Question 1d:** </span>  What is the length of the longest transaction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145\r\n"
     ]
    }
   ],
   "source": [
    "!awk '(NR==1||length> longest){longest=length} END {print longest}' accidents_10k.dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">**Answer:** </span>  length of smallest transaction : 145"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Question 1e:** </span>  What is the size of the search space of frequent itemsets in this data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod u+x apriori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">**Answer:** </span> search space :2^itemsets = 2^310"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Question 1f:** </span> \n",
    "Assume that you work for the deparment of transportation that collected this data. What benefit do you see in using itemset mining approaches on this data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">**Answer:** </span> we can analyze the sequence of accidents that occured using the data. prevention measure are taken where they are large accidents and etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Question 1g:** </span>  What type of itemsets (frequent, maximial or closed) would you be interested in discovering this dataset? State your reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">**Answer:** </span> finding the closed itemsets is interested. as we can get frequent itemsets and also its support."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Question 1h:** </span>  What minsup threshold would you use and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "the minsup threshold i would use is 1500 . it depends upon the support and confidence of the itemset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Generating frequent, maximal and closed itemsets using $\\color{red}{\\text{Apriori}}$, $\\color{red}{\\text{ECLAT}}$, and $\\color{red}{\\text{FPGrowth}}$ algorihtms from the dataset accidents_10k.dat "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Question 2a:** </span> Generate frequent itemsets using Apriori, for minsup = 2000, 3000, and 4000. Which of these minsup thresholds results in a maximum number of frequent itemsets? Which of these minsup thresholds results in a least number of frequent itemsets? Provide a rationale for these observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!chmod u+x apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: ./apriori [options] infile [outfile]\r\n",
      "find frequent item sets with the apriori algorithm\r\n",
      "version 6.27 (2017.08.01)        (c) 1996-2017   Christian Borgelt\r\n",
      "-t#      target type                              (default: s)\r\n",
      "         (s: frequent, c: closed, m: maximal item sets,\r\n",
      "          g: generators, r: association rules)\r\n",
      "-m#      minimum number of items per set/rule     (default: 1)\r\n",
      "-n#      maximum number of items per set/rule     (default: no limit)\r\n",
      "-s#      minimum support of an item set/rule      (default: 10%)\r\n",
      "-S#      maximum support of an item set/rule      (default: 100%)\r\n",
      "         (positive: percentage, negative: absolute number)\r\n",
      "-o       use original rule support definition     (body & head)\r\n",
      "-c#      minimum confidence of an assoc. rule     (default: 80%)\r\n",
      "-e#      additional evaluation measure            (default: none)\r\n",
      "-a#      aggregation mode for evaluation measure  (default: none)\r\n",
      "-d#      threshold for add. evaluation measure    (default: 10%)\r\n",
      "-i       invalidate eval. below expected support  (default: evaluate all)\r\n",
      "-p#      (min. size for) pruning with evaluation  (default: no pruning)\r\n",
      "         (< 0: weak forward, > 0 strong forward, = 0: backward pruning)\r\n",
      "-q#      sort items w.r.t. their frequency        (default: 2)\r\n",
      "         (1: ascending, -1: descending, 0: do not sort,\r\n",
      "          2: ascending, -2: descending w.r.t. transaction size sum)\r\n",
      "-u#      filter unused items from transactions    (default: 0.01)\r\n",
      "         (0: do not filter items w.r.t. usage in sets,\r\n",
      "         <0: fraction of removed items for filtering,\r\n",
      "         >0: take execution times ratio into account)\r\n",
      "-x       do not prune with perfect extensions     (default: prune)\r\n",
      "-y       a-posteriori pruning of infrequent item sets\r\n",
      "-T       do not organize transactions as a prefix tree\r\n",
      "-F#:#..  support border for filtering item sets   (default: none)\r\n",
      "         (list of minimum support values, one per item set size,\r\n",
      "         starting at the minimum size, as given with option -m#)\r\n",
      "-R#      read item selection/appearance indicators\r\n",
      "-P#      write a pattern spectrum to a file\r\n",
      "-Z       print item set statistics (number of item sets per size)\r\n",
      "-N       do not pre-format some integer numbers   (default: do)\r\n",
      "-g       write item names in scanable form (quote certain characters)\r\n",
      "-h#      record header  for output                (default: \"\")\r\n",
      "-k#      item separator for output                (default: \" \")\r\n",
      "-I#      implication sign for association rules   (default: \" <- \")\r\n",
      "-v#      output format for set/rule information   (default: \" (%S)\")\r\n",
      "-j#      sort item sets in output by their size   (default: no sorting)\r\n",
      "         (< 0: descending, > 0: ascending order)\r\n",
      "-w       integer transaction weight in last field (default: only items)\r\n",
      "-r#      record/transaction separators            (default: \"\\n\")\r\n",
      "-f#      field /item        separators            (default: \" \\t,\")\r\n",
      "-b#      blank   characters                       (default: \" \\t\\r\")\r\n",
      "-C#      comment characters                       (default: \"#\")\r\n",
      "-!       print additional option information\r\n",
      "infile   file to read transactions from           [required]\r\n",
      "outfile  file to write item sets/assoc. rules to  [optional]\r\n"
     ]
    }
   ],
   "source": [
    "!./apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./apriori - find frequent item sets with the apriori algorithm\n",
      "version 6.27 (2017.08.01)        (c) 1996-2017   Christian Borgelt\n",
      "reading accidents_10k.dat ... [310 item(s), 10000 transaction(s)] done [0.02s].\n",
      "filtering, sorting and recoding items ... [49 item(s)] done [0.00s].\n",
      "sorting and reducing transactions ... [9951/10000 transaction(s)] done [0.01s].\n",
      "building transaction tree ... [20250 node(s)] done [0.01s].\n",
      "checking subsets of size 1 2 3 4 5 6 7 8 9 10 11 12 13 done [19.75s].\n",
      "writing T_Accidents_2000.txt ... [851034 set(s)] done [0.10s].\n"
     ]
    }
   ],
   "source": [
    "!./apriori -ts -s-2000 accidents_10k.dat T_Accidents_2000.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./apriori - find frequent item sets with the apriori algorithm\n",
      "version 6.27 (2017.08.01)        (c) 1996-2017   Christian Borgelt\n",
      "reading accidents_10k.dat ... [310 item(s), 10000 transaction(s)] done [0.01s].\n",
      "filtering, sorting and recoding items ... [33 item(s)] done [0.01s].\n",
      "sorting and reducing transactions ... [9381/10000 transaction(s)] done [0.00s].\n",
      "building transaction tree ... [22267 node(s)] done [0.01s].\n",
      "checking subsets of size 1 2 3 4 5 6 7 8 9 10 11 done [1.39s].\n",
      "writing T_Accidents_4000.txt ... [29501 set(s)] done [0.00s].\n"
     ]
    }
   ],
   "source": [
    "!./apriori -ts -s-4000 accidents_10k.dat T_Accidents_4000.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./apriori - find frequent item sets with the apriori algorithm\n",
      "version 6.27 (2017.08.01)        (c) 1996-2017   Christian Borgelt\n",
      "reading accidents_10k.dat ... [310 item(s), 10000 transaction(s)] done [0.02s].\n",
      "filtering, sorting and recoding items ... [38 item(s)] done [0.00s].\n",
      "sorting and reducing transactions ... [9674/10000 transaction(s)] done [0.01s].\n",
      "building transaction tree ... [24741 node(s)] done [0.01s].\n",
      "checking subsets of size 1 2 3 4 5 6 7 8 9 10 11 12 done [4.38s].\n",
      "writing T_Accidents_3000.txt ... [133799 set(s)] done [0.01s].\n"
     ]
    }
   ],
   "source": [
    "!./apriori -ts -s-3000 accidents_10k.dat T_Accidents_3000.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">**Answer:** </span> the maximum number of frequent set resulted is 851034 when minsup threshold is 2000 \n",
    "\n",
    "the minimum number of frequent sets resulted is 29501 for minsup = 4000 \n",
    "\n",
    "as the minsup threshold increases the resultant number of frequent set decreases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Question 2b:** </span>   Using Apriori, compare the execution time for finding frequent itemsets for minsup = 2000, 3000, and 4000. Which of these minsup thresholds takes the least amount of time? Provide a rationale for this observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./apriori - find frequent item sets with the apriori algorithm\n",
      "version 6.27 (2017.08.01)        (c) 1996-2017   Christian Borgelt\n",
      "reading accidents_10k.dat ... [310 item(s), 10000 transaction(s)] done [0.02s].\n",
      "filtering, sorting and recoding items ... [49 item(s)] done [0.00s].\n",
      "sorting and reducing transactions ... [9951/10000 transaction(s)] done [0.00s].\n",
      "building transaction tree ... [20250 node(s)] done [0.01s].\n",
      "checking subsets of size 1 2 3 4 5 6 7 8 9 10 11 12 13 done [18.30s].\n",
      "writing <null> ... [851034 set(s)] done [0.02s].\n",
      "18 secs  611808 microsecs\n"
     ]
    }
   ],
   "source": [
    "import datetime \n",
    "start = datetime.datetime.now()\n",
    "!./apriori -ts -s-2000 accidents_10k.dat \n",
    "end = datetime.datetime.now()\n",
    "elapsed = end - start\n",
    "print(elapsed.seconds,\"secs \",elapsed.microseconds,\"microsecs\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./apriori - find frequent item sets with the apriori algorithm\n",
      "version 6.27 (2017.08.01)        (c) 1996-2017   Christian Borgelt\n",
      "reading accidents_10k.dat ... [310 item(s), 10000 transaction(s)] done [0.03s].\n",
      "filtering, sorting and recoding items ... [38 item(s)] done [0.00s].\n",
      "sorting and reducing transactions ... [9674/10000 transaction(s)] done [0.01s].\n",
      "building transaction tree ... [24741 node(s)] done [0.00s].\n",
      "checking subsets of size 1 2 3 4 5 6 7 8 9 10 11 12 done [4.50s].\n",
      "writing <null> ... [133799 set(s)] done [0.00s].\n",
      "5 secs  421554 microsecs\n"
     ]
    }
   ],
   "source": [
    "import datetime \n",
    "start = datetime.datetime.now()\n",
    "!./apriori -ts -s-3000 accidents_10k.dat \n",
    "end = datetime.datetime.now()\n",
    "elapsed = end - start\n",
    "print(elapsed.seconds,\"secs \",elapsed.microseconds,\"microsecs\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./apriori - find frequent item sets with the apriori algorithm\n",
      "version 6.27 (2017.08.01)        (c) 1996-2017   Christian Borgelt\n",
      "reading accidents_10k.dat ... [310 item(s), 10000 transaction(s)] done [0.02s].\n",
      "filtering, sorting and recoding items ... [33 item(s)] done [0.01s].\n",
      "sorting and reducing transactions ... [9381/10000 transaction(s)] done [0.00s].\n",
      "building transaction tree ... [22267 node(s)] done [0.00s].\n",
      "checking subsets of size 1 2 3 4 5 6 7 8 9 10 11 done [1.33s].\n",
      "writing <null> ... [29501 set(s)] done [0.00s].\n",
      "1 secs  675855 microsecs\n"
     ]
    }
   ],
   "source": [
    "import datetime \n",
    "start = datetime.datetime.now()\n",
    "!./apriori -ts -s-4000 accidents_10k.dat \n",
    "end = datetime.datetime.now()\n",
    "elapsed = end - start\n",
    "print(elapsed.seconds,\"secs \",elapsed.microseconds,\"microsecs\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">**Answer:** </span> For minsup = 4000 the execution takes the least amount of time and minsup = 1000 takes more amount of time. \n",
    "\n",
    "observation : from the above results the minsup threshold increases and the execution time decreases. since there are more frequent item sets when the minsup is low it takes more time when the threshold is less. its inversely proportional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Question 2c:** </span> Using Apriori, find the frequent itemsets for minsup = 2000, 3000, and 4000. Determine the number of itemsets for each size (1 to max length of an itemset). What trends do you see that are common for all three minsup thresholds? What trends do you see that are different? Provide a rationale for these observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************minsup = 2000******************************\n",
      "     49 1\n",
      "    705 2\n",
      "   5285 3\n",
      "  23745 4\n",
      "  69647 5\n",
      " 139628 6\n",
      " 195730 7\n",
      " 193299 8\n",
      " 133819 9\n",
      "  63937 10\n",
      "  20497 11\n",
      "   4189 12\n",
      "    483 13\n",
      "     21 14\n",
      "*****************minsup = 3000******************************\n",
      "     38 1\n",
      "    468 2\n",
      "   2830 3\n",
      "   9887 4\n",
      "  21779 5\n",
      "  31964 6\n",
      "  32020 7\n",
      "  21862 8\n",
      "   9839 9\n",
      "   2705 10\n",
      "    387 11\n",
      "     20 12\n",
      "*****************minsup = 4000******************************\n",
      "     33 1\n",
      "    319 2\n",
      "   1492 3\n",
      "   4043 4\n",
      "   6926 5\n",
      "   7751 6\n",
      "   5626 7\n",
      "   2546 8\n",
      "    668 9\n",
      "     91 10\n",
      "      6 11\n"
     ]
    }
   ],
   "source": [
    "print(\"*****************minsup = 2000******************************\")\n",
    "!awk '{print NF-1}' T_Accidents_2000.txt|sort -n|uniq -c\n",
    "print(\"*****************minsup = 3000******************************\")\n",
    "!awk '{print NF-1}' T_Accidents_3000.txt|sort -n|uniq -c\n",
    "print(\"*****************minsup = 4000******************************\")\n",
    "!awk '{print NF-1}' T_Accidents_4000.txt|sort -n|uniq -c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">**Answer:** </span> \n",
    "the number of itemsets decreases as minsup threshold increases from the above result. and the number of frequent sets also decreases for each item as minsup threshold increases.\n",
    "\n",
    "for each minup threshold the number of itemsets follows the bell curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Question 2d:** </span>  Using Apriori with minsup=2000, compare the number of frequent, maximal, and closed itemsets. Which is the largest set and which is the smallest set? Provide a rationale for these observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************frequent item set******************************\n",
      "./apriori - find frequent item sets with the apriori algorithm\n",
      "version 6.27 (2017.08.01)        (c) 1996-2017   Christian Borgelt\n",
      "reading accidents_10k.dat ... [310 item(s), 10000 transaction(s)] done [0.02s].\n",
      "filtering, sorting and recoding items ... [49 item(s)] done [0.00s].\n",
      "sorting and reducing transactions ... [9951/10000 transaction(s)] done [0.01s].\n",
      "building transaction tree ... [20250 node(s)] done [0.00s].\n",
      "checking subsets of size 1 2 3 4 5 6 7 8 9 10 11 12 13 done [19.37s].\n",
      "writing T_Accidents_frequent_2000.txt ... [851034 set(s)] done [0.10s].\n",
      "*****************closed item set******************************\n",
      "./apriori - find frequent item sets with the apriori algorithm\n",
      "version 6.27 (2017.08.01)        (c) 1996-2017   Christian Borgelt\n",
      "reading accidents_10k.dat ... [310 item(s), 10000 transaction(s)] done [0.03s].\n",
      "filtering, sorting and recoding items ... [49 item(s)] done [0.00s].\n",
      "sorting and reducing transactions ... [9951/10000 transaction(s)] done [0.01s].\n",
      "building transaction tree ... [20250 node(s)] done [0.00s].\n",
      "checking subsets of size 1 2 3 4 5 6 7 8 9 10 11 12 13 14 done [29.95s].\n",
      "filtering for closed item sets ... done [0.47s].\n",
      "writing T_Accidents_closed_2000.txt ... [519902 set(s)] done [0.09s].\n",
      "*****************maximal item set******************************\n",
      "./apriori - find frequent item sets with the apriori algorithm\n",
      "version 6.27 (2017.08.01)        (c) 1996-2017   Christian Borgelt\n",
      "reading T10I4D100K_new.dat ... [870 item(s), 99936 transaction(s)] done [0.06s].\n",
      "filtering, sorting and recoding items ... [155 item(s)] done [0.00s].\n",
      "sorting and reducing transactions ... [75349/99936 transaction(s)] done [0.02s].\n",
      "building transaction tree ... [93819 node(s)] done [0.01s].\n",
      "checking subsets of size 1 2 done [0.01s].\n",
      "filtering for maximal item sets ... done [0.00s].\n",
      "writing T_Accidents_maximal_2000.txt ... [155 set(s)] done [0.00s].\n"
     ]
    }
   ],
   "source": [
    "print(\"*****************frequent item set******************************\")\n",
    "!./apriori -ts -s-2000 accidents_10k.dat T_Accidents_frequent_2000.txt\n",
    "print(\"*****************closed item set******************************\")\n",
    "!./apriori -tc -s-2000 accidents_10k.dat T_Accidents_closed_2000.txt\n",
    "print(\"*****************maximal item set******************************\")\n",
    "!./apriori -tm -s-2000 T10I4D100K_new.dat T_Accidents_maximal_2000.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">**Answer:** </span> the frequent item set is the largest and the maximal itemset is smallest.\n",
    "\n",
    "the maximal item set (subset of) closed item set (subset of) frequent itemset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Question 2e:** </span> For a minsup = 2000, compare the execution time for Apriori, ECLAT and FPGrowth. Which of these algorithms took the least amount of time. Provide a rationale for this observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod u+x eclat\n",
    "!chmod u+x fpgrowth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************apriori*************************\n",
      "./apriori - find frequent item sets with the apriori algorithm\n",
      "version 6.27 (2017.08.01)        (c) 1996-2017   Christian Borgelt\n",
      "reading accidents_10k.dat ... [310 item(s), 10000 transaction(s)] done [0.02s].\n",
      "filtering, sorting and recoding items ... [49 item(s)] done [0.01s].\n",
      "sorting and reducing transactions ... [9951/10000 transaction(s)] done [0.00s].\n",
      "building transaction tree ... [20250 node(s)] done [0.01s].\n",
      "checking subsets of size 1 2 3 4 5 6 7 8 9 10 11 12 13 done [19.88s].\n",
      "writing <null> ... [851034 set(s)] done [0.01s].\n",
      "20 secs  395722 microsecs\n",
      "*****************fpgrowth*************************\n",
      "./fpgrowth - find frequent item sets with the fpgrowth algorithm\n",
      "version 6.18 (2019.03.31)        (c) 2004-2019   Christian Borgelt\n",
      "reading accidents_10k.dat ... [310 item(s), 10000 transaction(s)] done [0.02s].\n",
      "filtering, sorting and recoding items ... [49 item(s)] done [0.00s].\n",
      "sorting and reducing transactions ... [9951/10000 transaction(s)] done [0.01s].\n",
      "writing <null> ... [851034 set(s)] done [0.08s].\n",
      "0 secs  549476 microsecs\n",
      "*****************eclat*************************\n",
      "./eclat - find frequent item sets with the eclat algorithm\n",
      "version 5.20 (2017.05.30)        (c) 2002-2017   Christian Borgelt\n",
      "reading accidents_10k.dat ... [310 item(s), 10000 transaction(s)] done [0.01s].\n",
      "filtering, sorting and recoding items ... [49 item(s)] done [0.01s].\n",
      "sorting and reducing transactions ... [9951/10000 transaction(s)] done [0.00s].\n",
      "writing <null> ... [851034 set(s)] done [0.28s].\n",
      "0 secs  742595 microsecs\n"
     ]
    }
   ],
   "source": [
    "import datetime \n",
    "algo = {\"apriori\",\"eclat\",\"fpgrowth\"}\n",
    "for i in algo:\n",
    "    start = datetime.datetime.now()\n",
    "    ! printf \"*****************\"\"$i\"\"*************************\\n\"\n",
    "    !./\"$i\" -ts -s-2000 accidents_10k.dat \n",
    "    end = datetime.datetime.now()\n",
    "    elapsed = end - start\n",
    "    print(elapsed.seconds,\"secs \",elapsed.microseconds,\"microsecs\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">**Answer:** </span> the FP growth algorithm tooks the least amount of time for the execution. as the computing time of fp growth algorithm is less than other algorithms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Question 2f:** </span> For a minsup = 4000, compare the execution time for Apriori, ECLAT and FPGrowth. Which of these algorithms took the least amount of time. Provide a rationale for this observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************apriori*************************\n",
      "./apriori - find frequent item sets with the apriori algorithm\n",
      "version 6.27 (2017.08.01)        (c) 1996-2017   Christian Borgelt\n",
      "reading accidents_10k.dat ... [310 item(s), 10000 transaction(s)] done [0.02s].\n",
      "filtering, sorting and recoding items ... [33 item(s)] done [0.00s].\n",
      "sorting and reducing transactions ... [9381/10000 transaction(s)] done [0.01s].\n",
      "building transaction tree ... [22267 node(s)] done [0.00s].\n",
      "checking subsets of size 1 2 3 4 5 6 7 8 9 10 11 done [1.16s].\n",
      "writing <null> ... [29501 set(s)] done [0.00s].\n",
      "1 secs  473746 microsecs\n",
      "*****************fpgrowth*************************\n",
      "./fpgrowth - find frequent item sets with the fpgrowth algorithm\n",
      "version 6.18 (2019.03.31)        (c) 2004-2019   Christian Borgelt\n",
      "reading accidents_10k.dat ... [310 item(s), 10000 transaction(s)] done [0.02s].\n",
      "filtering, sorting and recoding items ... [33 item(s)] done [0.00s].\n",
      "sorting and reducing transactions ... [9381/10000 transaction(s)] done [0.01s].\n",
      "writing <null> ... [29501 set(s)] done [0.02s].\n",
      "0 secs  309759 microsecs\n",
      "*****************eclat*************************\n",
      "./eclat - find frequent item sets with the eclat algorithm\n",
      "version 5.20 (2017.05.30)        (c) 2002-2017   Christian Borgelt\n",
      "reading accidents_10k.dat ... [310 item(s), 10000 transaction(s)] done [0.02s].\n",
      "filtering, sorting and recoding items ... [33 item(s)] done [0.00s].\n",
      "sorting and reducing transactions ... [9381/10000 transaction(s)] done [0.01s].\n",
      "writing <null> ... [29501 set(s)] done [0.05s].\n",
      "0 secs  323376 microsecs\n"
     ]
    }
   ],
   "source": [
    "import datetime \n",
    "algo = {\"apriori\",\"eclat\",\"fpgrowth\"}\n",
    "for i in algo:\n",
    "    ! printf \"*****************\"\"$i\"\"*************************\\n\"\n",
    "    start = datetime.datetime.now()\n",
    "    !./\"$i\" -ts -s-4000 accidents_10k.dat \n",
    "    end = datetime.datetime.now()\n",
    "    elapsed = end - start\n",
    "    print(elapsed.seconds,\"secs \",elapsed.microseconds,\"microsecs\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">**Answer:** </span> when the minsup threshold = 4000 the execution time is least for fpgrowth algorithm. it is beacuase of the computing time is efficient for the algorithm. the time difference between fp growth and eclat is less\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Question 2g:** </span>  For a minsup = 6000, compare the execution time for Apriori, ECLAT and FPGrowth. Which of these algorithms took the least amount of time. Provide a rationale for this observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************apriori*************************\n",
      "./apriori - find frequent item sets with the apriori algorithm\n",
      "version 6.27 (2017.08.01)        (c) 1996-2017   Christian Borgelt\n",
      "reading accidents_10k.dat ... [310 item(s), 10000 transaction(s)] done [0.02s].\n",
      "filtering, sorting and recoding items ... [20 item(s)] done [0.00s].\n",
      "sorting and reducing transactions ... [3216/10000 transaction(s)] done [0.01s].\n",
      "building transaction tree ... [6478 node(s)] done [0.00s].\n",
      "checking subsets of size 1 2 3 4 5 6 7 8 done [0.04s].\n",
      "writing <null> ... [2254 set(s)] done [0.00s].\n",
      "0 secs  306305 microsecs\n",
      "*****************fpgrowth*************************\n",
      "./fpgrowth - find frequent item sets with the fpgrowth algorithm\n",
      "version 6.18 (2019.03.31)        (c) 2004-2019   Christian Borgelt\n",
      "reading accidents_10k.dat ... [310 item(s), 10000 transaction(s)] done [0.02s].\n",
      "filtering, sorting and recoding items ... [20 item(s)] done [0.00s].\n",
      "sorting and reducing transactions ... [3216/10000 transaction(s)] done [0.01s].\n",
      "writing <null> ... [2254 set(s)] done [0.00s].\n",
      "0 secs  272344 microsecs\n",
      "*****************eclat*************************\n",
      "./eclat - find frequent item sets with the eclat algorithm\n",
      "version 5.20 (2017.05.30)        (c) 2002-2017   Christian Borgelt\n",
      "reading accidents_10k.dat ... [310 item(s), 10000 transaction(s)] done [0.02s].\n",
      "filtering, sorting and recoding items ... [20 item(s)] done [0.00s].\n",
      "sorting and reducing transactions ... [3216/10000 transaction(s)] done [0.01s].\n",
      "writing <null> ... [2254 set(s)] done [0.00s].\n",
      "0 secs  281052 microsecs\n"
     ]
    }
   ],
   "source": [
    "import datetime \n",
    "algo = {\"apriori\",\"eclat\",\"fpgrowth\"}\n",
    "for i in algo:\n",
    "    ! printf \"*****************\"\"$i\"\"*************************\\n\"\n",
    "    start = datetime.datetime.now()\n",
    "    !./\"$i\" -ts -s-6000 accidents_10k.dat \n",
    "    end = datetime.datetime.now()\n",
    "    elapsed = end - start\n",
    "    print(elapsed.seconds,\"secs \",elapsed.microseconds,\"microsecs\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">**Answer:** </span>  when minsup = 6000 the  fpgrowth algorithm works faster but its alsmost equal to eclat algorithm as the difference is of nanosecs.\n",
    "\n",
    "moreover as the minsup increases the execution time decreases and 3 algorithms are working efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Question 2h:** </span> Fill the following table based on execution times computed in __2e__, __2f__, and __2g__. State your observations on the relative computational efficiency at different support thresholds. Based on your knowledge of these algorithms, provide the reasons behind your observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************apriori*************************\n",
      "*****************6000*************************\n",
      "./apriori - find frequent item sets with the apriori algorithm\n",
      "version 6.27 (2017.08.01)        (c) 1996-2017   Christian Borgelt\n",
      "reading accidents_10k.dat ... [310 item(s), 10000 transaction(s)] done [0.02s].\n",
      "filtering, sorting and recoding items ... [20 item(s)] done [0.00s].\n",
      "sorting and reducing transactions ... [3216/10000 transaction(s)] done [0.00s].\n",
      "building transaction tree ... [6478 node(s)] done [0.00s].\n",
      "checking subsets of size 1 2 3 4 5 6 7 8 done [0.04s].\n",
      "writing <null> ... [2254 set(s)] done [0.00s].\n",
      "0 secs  319735 microsecs\n",
      "*****************4000*************************\n",
      "./apriori - find frequent item sets with the apriori algorithm\n",
      "version 6.27 (2017.08.01)        (c) 1996-2017   Christian Borgelt\n",
      "reading accidents_10k.dat ... [310 item(s), 10000 transaction(s)] done [0.02s].\n",
      "filtering, sorting and recoding items ... [33 item(s)] done [0.00s].\n",
      "sorting and reducing transactions ... [9381/10000 transaction(s)] done [0.00s].\n",
      "building transaction tree ... [22267 node(s)] done [0.00s].\n",
      "checking subsets of size 1 2 3 4 5 6 7 8 9 10 11 done [1.02s].\n",
      "writing <null> ... [29501 set(s)] done [0.00s].\n",
      "1 secs  288746 microsecs\n",
      "*****************2000*************************\n",
      "./apriori - find frequent item sets with the apriori algorithm\n",
      "version 6.27 (2017.08.01)        (c) 1996-2017   Christian Borgelt\n",
      "reading accidents_10k.dat ... [310 item(s), 10000 transaction(s)] done [0.02s].\n",
      "filtering, sorting and recoding items ... [49 item(s)] done [0.00s].\n",
      "sorting and reducing transactions ... [9951/10000 transaction(s)] done [0.01s].\n",
      "building transaction tree ... [20250 node(s)] done [0.00s].\n",
      "checking subsets of size 1 2 3 4 5 6 7 8 9 10 11 12 13 done [19.09s].\n",
      "writing <null> ... [851034 set(s)] done [0.01s].\n",
      "19 secs  402198 microsecs\n",
      "*****************fpgrowth*************************\n",
      "*****************6000*************************\n",
      "./fpgrowth - find frequent item sets with the fpgrowth algorithm\n",
      "version 6.18 (2019.03.31)        (c) 2004-2019   Christian Borgelt\n",
      "reading accidents_10k.dat ... [310 item(s), 10000 transaction(s)] done [0.03s].\n",
      "filtering, sorting and recoding items ... [20 item(s)] done [0.00s].\n",
      "sorting and reducing transactions ... [3216/10000 transaction(s)] done [0.00s].\n",
      "writing <null> ... [2254 set(s)] done [0.00s].\n",
      "0 secs  282791 microsecs\n",
      "*****************4000*************************\n",
      "./fpgrowth - find frequent item sets with the fpgrowth algorithm\n",
      "version 6.18 (2019.03.31)        (c) 2004-2019   Christian Borgelt\n",
      "reading accidents_10k.dat ... [310 item(s), 10000 transaction(s)] done [0.02s].\n",
      "filtering, sorting and recoding items ... [33 item(s)] done [0.00s].\n",
      "sorting and reducing transactions ... [9381/10000 transaction(s)] done [0.01s].\n",
      "writing <null> ... [29501 set(s)] done [0.01s].\n",
      "0 secs  299857 microsecs\n",
      "*****************2000*************************\n",
      "./fpgrowth - find frequent item sets with the fpgrowth algorithm\n",
      "version 6.18 (2019.03.31)        (c) 2004-2019   Christian Borgelt\n",
      "reading accidents_10k.dat ... [310 item(s), 10000 transaction(s)] done [0.03s].\n",
      "filtering, sorting and recoding items ... [49 item(s)] done [0.00s].\n",
      "sorting and reducing transactions ... [9951/10000 transaction(s)] done [0.01s].\n",
      "writing <null> ... [851034 set(s)] done [0.12s].\n",
      "0 secs  418950 microsecs\n",
      "*****************eclat*************************\n",
      "*****************6000*************************\n",
      "./eclat - find frequent item sets with the eclat algorithm\n",
      "version 5.20 (2017.05.30)        (c) 2002-2017   Christian Borgelt\n",
      "reading accidents_10k.dat ... [310 item(s), 10000 transaction(s)] done [0.02s].\n",
      "filtering, sorting and recoding items ... [20 item(s)] done [0.00s].\n",
      "sorting and reducing transactions ... [3216/10000 transaction(s)] done [0.01s].\n",
      "writing <null> ... [2254 set(s)] done [0.00s].\n",
      "0 secs  283213 microsecs\n",
      "*****************4000*************************\n",
      "./eclat - find frequent item sets with the eclat algorithm\n",
      "version 5.20 (2017.05.30)        (c) 2002-2017   Christian Borgelt\n",
      "reading accidents_10k.dat ... [310 item(s), 10000 transaction(s)] done [0.03s].\n",
      "filtering, sorting and recoding items ... [33 item(s)] done [0.00s].\n",
      "sorting and reducing transactions ... [9381/10000 transaction(s)] done [0.01s].\n",
      "writing <null> ... [29501 set(s)] done [0.06s].\n",
      "0 secs  342196 microsecs\n",
      "*****************2000*************************\n",
      "./eclat - find frequent item sets with the eclat algorithm\n",
      "version 5.20 (2017.05.30)        (c) 2002-2017   Christian Borgelt\n",
      "reading accidents_10k.dat ... [310 item(s), 10000 transaction(s)] done [0.02s].\n",
      "filtering, sorting and recoding items ... [49 item(s)] done [0.00s].\n",
      "sorting and reducing transactions ... [9951/10000 transaction(s)] done [0.01s].\n",
      "writing <null> ... [851034 set(s)] done [0.26s].\n",
      "0 secs  532076 microsecs\n"
     ]
    }
   ],
   "source": [
    "import datetime \n",
    "algo = {\"apriori\",\"eclat\",\"fpgrowth\"}\n",
    "minsup ={2000,4000,6000}\n",
    "for i in algo:\n",
    "    ! printf \"*****************\"\"$i\"\"*************************\\n\"\n",
    "    for j in minsup:\n",
    "        ! printf \"*****************\"\"$j\"\"*************************\\n\"\n",
    "        start = datetime.datetime.now()\n",
    "        !./\"$i\" -ts -s-\"$j\" accidents_10k.dat \n",
    "        end = datetime.datetime.now()\n",
    "        elapsed = end - start\n",
    "        print(elapsed.seconds,\"secs \",elapsed.microseconds,\"microsecs\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<span style=\"color:green\">Answer: </span>\n",
    "    \n",
    "|   Algorithm                |minsup=2000                   |minsup=4000                      |minsup=6000                 |\n",
    "|----------------------------|------------------------------|---------------------------------|----------------------------| \n",
    "|Apriori                     | 19 secs  402198 microsecs    |     1 secs  288746 microsecs    |   0 secs  319735 microsecs |\n",
    "|Eclat                       | 0 secs  532076 microsecs     |     0 secs  342196 microsecs    |   0 secs  283213 microsecs |\n",
    "|FPGrowth                    | 0 secs  418950 microsecs     |     0 secs  299857 microsecs    |   0 secs  282791 microsecs |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">**Answer:** </span> from the above comparisions the FP growth algorithm  works faster for the given data set when minsup = 2000,4000 and 6000 ,also as minsup threshold increase it works even more faster as it contains less number of itemsets.\n",
    "\n",
    " As the minup increases the difference in time between the algorithm decreases which you can clearly observe at minsup = 6000\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Discovering frequent subsequences and substrings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume that roads in a Cincinnati are assigned numbers. Participants are enrolled in a transportation study and for every trip they make using their car, the sequence of roads taken are recorded. Trips that involves freeways are excluded. This data is in the file <span style=\"color:blue\">road_seq_data.dat</span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod u+x prefixspan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Question 3a:** </span>  What 'type' of sequence mining will you perform to determine frequently taken 'paths'? Paths are sequences of roads traveresed consecutively in the same order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">**Answer:** </span> We perform sequence mining here as the transportation of students is different and anaysis using the subsequence patterns will do good for the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Question 3b:** </span> How many sequences are there in this sequence database?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 road_seq_data.dat\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l road_seq_data.dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">**Answer:** </span> 1000 sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Question 3c:** </span> What is the size of the alphabet in this sequence database?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1283\r\n"
     ]
    }
   ],
   "source": [
    "!awk -- '{for (alphabet = 1; alphabet <= NF; alphabet++) wc[$alphabet] += 1}; END {print length(wc)}' road_seq_data.dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">**Answer:** </span>  the size of alphabet is the number of items in the sequence database - 1283"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Question 3d:** </span> What are the total number of possible subsequences of length 2 in this dataset?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "there will be n*n subsequnces in itemset size n . so there are 1283^2 subsequences possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Question 3e:** </span> What are the total number of possible substrings of length 2 in this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod u+x seqwog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there will be 1282 substring possible as there are 1283 items are present in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Question 3f:** </span> Discover frequent __subsequences__ with minsup = 10 and report the number of subsequences discovered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./prefixspan - sequence mining with unique occurrences of items and weight averaging\n",
      "version 2.16 (2016.10.15)        (c) 2010-2016   Christian Borgelt\n",
      "reading road_seq_data.dat ... [1283 item(s), 1000 transaction(s)] done [0.01s].\n",
      "recoding items ... [1283 item(s)] done [0.00s].\n",
      "filtering and reducing transactions ... [910/1000 transaction(s)] done [0.00s].\n",
      "writing road_seq_data_minsup_10_prefix.txt ... [4588 sequence(s)] done [0.04s].\n"
     ]
    }
   ],
   "source": [
    "!./prefixspan -ts -s-10 road_seq_data.dat road_seq_data_minsup_10_prefix.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">**Answer:** </span> there are 4588 frequent subsequnces when minsup = 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Question 3g:** </span>  Discover frequent __substrings__ with minsup = 10 and report the number of substrings discovered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./seqwog - find frequent sequences without gaps\r\n",
      "version 3.16 (2016.10.15)        (c) 2010-2016   Christian Borgelt\r\n",
      "reading road_seq_data.dat ... [1283 item(s), 1000 transaction(s)] done [0.00s].\r\n",
      "recoding items ... [1283 item(s)] done [0.00s].\r\n",
      "reducing and triming transactions ... [844/1000 transaction(s)] done [0.00s].\r\n",
      "writing road_seq_data_minsup_10.txt ... [613 sequence(s)] done [0.01s].\r\n"
     ]
    }
   ],
   "source": [
    "!./seqwog -ts -s-10 road_seq_data.dat road_seq_data_minsup_10.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">**Answer:** </span> 613 substrings are discovered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Question 3h:** </span> Explain the difference in the number of frequent subsequences and substrings found in __3f__ and __3g__ above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">**Answer:** </span> the frequent subsequences are more than the frequent substrings as the substring are the immediate items but the subsequences can be anywhere but follows the order in the given set. so subsequences are generally more than the substrings in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3.5 [python/3.5 ]",
   "language": "python",
   "name": "sys_python35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
